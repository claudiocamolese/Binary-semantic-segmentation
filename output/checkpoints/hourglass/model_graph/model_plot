digraph {
	graph [size="22.349999999999998,22.349999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	134181113379600 [label="
 (2, 1, 128, 128)" fillcolor=darkolivegreen1]
	134181115640560 [label=ConvolutionBackward0]
	134181115640320 -> 134181115640560
	134181115640320 [label=ConvolutionBackward0]
	134181115640800 -> 134181115640320
	134181115640800 [label=ReluBackward0]
	134181115641040 -> 134181115640800
	134181115641040 [label=ConvolutionBackward0]
	134181115640656 -> 134181115641040
	134181115640656 [label=ConvolutionBackward0]
	134181115638784 -> 134181115640656
	134181115638784 [label=ReluBackward0]
	134181115641808 -> 134181115638784
	134181115641808 [label=ConvolutionBackward0]
	134181115641568 -> 134181115641808
	134181115641568 [label=ConvolutionBackward0]
	134181115641232 -> 134181115641568
	134181115641232 [label=ReluBackward0]
	134181119668096 -> 134181115641232
	134181119668096 [label=ConvolutionBackward0]
	134181119473264 -> 134181119668096
	134181119473264 [label=MaxPool2DWithIndicesBackward0]
	134181115707456 -> 134181119473264
	134181115707456 [label=ConvolutionBackward0]
	134181115707600 -> 134181115707456
	134181115707600 [label=ReluBackward0]
	134181115707888 -> 134181115707600
	134181115707888 [label=ConvolutionBackward0]
	134181115708128 -> 134181115707888
	134181115708128 [label=MaxPool2DWithIndicesBackward0]
	134181115710000 -> 134181115708128
	134181115710000 [label=ConvolutionBackward0]
	134181115708560 -> 134181115710000
	134181115708560 [label=ReluBackward0]
	134181115710144 -> 134181115708560
	134181115710144 [label=ConvolutionBackward0]
	134181115708896 -> 134181115710144
	134181115708896 [label=MaxPool2DWithIndicesBackward0]
	134181115708800 -> 134181115708896
	134181115708800 [label=ConvolutionBackward0]
	134181115708848 -> 134181115708800
	134181115708848 [label=ReluBackward0]
	134181115709424 -> 134181115708848
	134181115709424 [label=ConvolutionBackward0]
	134181115708992 -> 134181115709424
	134181113376480 [label="encoder.0.layers.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	134181113376480 -> 134181115708992
	134181115708992 [label=AccumulateGrad]
	134181115709184 -> 134181115709424
	134181113376560 [label="encoder.0.layers.0.bias
 (16)" fillcolor=lightblue]
	134181113376560 -> 134181115709184
	134181115709184 [label=AccumulateGrad]
	134181115708656 -> 134181115708800
	134181113376720 [label="encoder.0.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	134181113376720 -> 134181115708656
	134181115708656 [label=AccumulateGrad]
	134181115708464 -> 134181115708800
	134181113376800 [label="encoder.0.layers.2.bias
 (16)" fillcolor=lightblue]
	134181113376800 -> 134181115708464
	134181115708464 [label=AccumulateGrad]
	134181115708368 -> 134181115710144
	134181113376960 [label="encoder.2.layers.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	134181113376960 -> 134181115708368
	134181115708368 [label=AccumulateGrad]
	134181115708272 -> 134181115710144
	134181113377040 [label="encoder.2.layers.0.bias
 (32)" fillcolor=lightblue]
	134181113377040 -> 134181115708272
	134181115708272 [label=AccumulateGrad]
	134181115707696 -> 134181115710000
	134181113377200 [label="encoder.2.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	134181113377200 -> 134181115707696
	134181115707696 [label=AccumulateGrad]
	134181115708176 -> 134181115710000
	134181113377280 [label="encoder.2.layers.2.bias
 (32)" fillcolor=lightblue]
	134181113377280 -> 134181115708176
	134181115708176 [label=AccumulateGrad]
	134181115708032 -> 134181115707888
	134181113377440 [label="encoder.4.layers.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	134181113377440 -> 134181115708032
	134181115708032 [label=AccumulateGrad]
	134181115707840 -> 134181115707888
	134181113377520 [label="encoder.4.layers.0.bias
 (64)" fillcolor=lightblue]
	134181113377520 -> 134181115707840
	134181115707840 [label=AccumulateGrad]
	134181115707552 -> 134181115707456
	134181113377680 [label="encoder.4.layers.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	134181113377680 -> 134181115707552
	134181115707552 [label=AccumulateGrad]
	134181115707504 -> 134181115707456
	134181113377760 [label="encoder.4.layers.2.bias
 (64)" fillcolor=lightblue]
	134181113377760 -> 134181115707504
	134181115707504 [label=AccumulateGrad]
	134181120397984 -> 134181119668096
	134181113377920 [label="decoder.0.layers.0.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	134181113377920 -> 134181120397984
	134181120397984 [label=AccumulateGrad]
	134181115712304 -> 134181119668096
	134181113378000 [label="decoder.0.layers.0.bias
 (32)" fillcolor=lightblue]
	134181113378000 -> 134181115712304
	134181115712304 [label=AccumulateGrad]
	134181115641616 -> 134181115641568
	134181113378160 [label="decoder.0.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	134181113378160 -> 134181115641616
	134181115641616 [label=AccumulateGrad]
	134181120397552 -> 134181115641568
	134181113378240 [label="decoder.0.layers.2.bias
 (32)" fillcolor=lightblue]
	134181113378240 -> 134181120397552
	134181120397552 [label=AccumulateGrad]
	134181115641760 -> 134181115641808
	134181113378400 [label="decoder.1.layers.0.weight
 (32, 16, 2, 2)" fillcolor=lightblue]
	134181113378400 -> 134181115641760
	134181115641760 [label=AccumulateGrad]
	134181115641424 -> 134181115641808
	134181113378480 [label="decoder.1.layers.0.bias
 (16)" fillcolor=lightblue]
	134181113378480 -> 134181115641424
	134181115641424 [label=AccumulateGrad]
	134181115640992 -> 134181115640656
	134181113378640 [label="decoder.1.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	134181113378640 -> 134181115640992
	134181115640992 [label=AccumulateGrad]
	134181115641088 -> 134181115640656
	134181113378720 [label="decoder.1.layers.2.bias
 (16)" fillcolor=lightblue]
	134181113378720 -> 134181115641088
	134181115641088 [label=AccumulateGrad]
	134181115640752 -> 134181115641040
	134181113378880 [label="decoder.2.layers.0.weight
 (16, 8, 2, 2)" fillcolor=lightblue]
	134181113378880 -> 134181115640752
	134181115640752 [label=AccumulateGrad]
	134181115640176 -> 134181115641040
	134181113378960 [label="decoder.2.layers.0.bias
 (8)" fillcolor=lightblue]
	134181113378960 -> 134181115640176
	134181115640176 [label=AccumulateGrad]
	134181115639936 -> 134181115640320
	134181113379120 [label="decoder.2.layers.2.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	134181113379120 -> 134181115639936
	134181115639936 [label=AccumulateGrad]
	134181115640416 -> 134181115640320
	134181113379200 [label="decoder.2.layers.2.bias
 (8)" fillcolor=lightblue]
	134181113379200 -> 134181115640416
	134181115640416 [label=AccumulateGrad]
	134181115640224 -> 134181115640560
	134181113379360 [label="conv.weight
 (1, 8, 1, 1)" fillcolor=lightblue]
	134181113379360 -> 134181115640224
	134181115640224 [label=AccumulateGrad]
	134181115640080 -> 134181115640560
	134181113379440 [label="conv.bias
 (1)" fillcolor=lightblue]
	134181113379440 -> 134181115640080
	134181115640080 [label=AccumulateGrad]
	134181115640560 -> 134181113379600
}
