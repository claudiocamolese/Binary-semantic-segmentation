digraph {
	graph [size="30.0,30.0"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	131169675496976 [label="
 (2, 1, 128, 128)" fillcolor=darkolivegreen1]
	131169679057360 [label=ConvolutionBackward0]
	131169683659824 -> 131169679057360
	131169683659824 [label=ReluBackward0]
	131169675464224 -> 131169683659824
	131169675464224 [label=ConvolutionBackward0]
	131169675464176 -> 131169675464224
	131169675464176 [label=ReluBackward0]
	131169675464704 -> 131169675464176
	131169675464704 [label=ConvolutionBackward0]
	131169675464608 -> 131169675464704
	131169675464608 [label=CatBackward0]
	131169675464944 -> 131169675464608
	131169675464944 [label=ConvolutionBackward0]
	131169675465088 -> 131169675464944
	131169675465088 [label=ReluBackward0]
	131169675465280 -> 131169675465088
	131169675465280 [label=ConvolutionBackward0]
	131169675465376 -> 131169675465280
	131169675465376 [label=ReluBackward0]
	131169675465568 -> 131169675465376
	131169675465568 [label=ConvolutionBackward0]
	131169675465664 -> 131169675465568
	131169675465664 [label=CatBackward0]
	131169675465856 -> 131169675465664
	131169675465856 [label=ConvolutionBackward0]
	131169675466000 -> 131169675465856
	131169675466000 [label=ReluBackward0]
	131169675466192 -> 131169675466000
	131169675466192 [label=ConvolutionBackward0]
	131169675466288 -> 131169675466192
	131169675466288 [label=ReluBackward0]
	131169675466480 -> 131169675466288
	131169675466480 [label=ConvolutionBackward0]
	131169675466576 -> 131169675466480
	131169675466576 [label=CatBackward0]
	131169675466768 -> 131169675466576
	131169675466768 [label=ConvolutionBackward0]
	131169675466912 -> 131169675466768
	131169675466912 [label=MaxPool2DWithIndicesBackward0]
	131169675466720 -> 131169675466912
	131169675466720 [label=ReluBackward0]
	131169675467152 -> 131169675466720
	131169675467152 [label=ConvolutionBackward0]
	131169675467248 -> 131169675467152
	131169675467248 [label=ReluBackward0]
	131169675467440 -> 131169675467248
	131169675467440 [label=ConvolutionBackward0]
	131169675467536 -> 131169675467440
	131169675467536 [label=MaxPool2DWithIndicesBackward0]
	131169675465808 -> 131169675467536
	131169675465808 [label=ReluBackward0]
	131169675467776 -> 131169675465808
	131169675467776 [label=ConvolutionBackward0]
	131169675467824 -> 131169675467776
	131169675467824 [label=ReluBackward0]
	131169675468112 -> 131169675467824
	131169675468112 [label=ConvolutionBackward0]
	131169675468160 -> 131169675468112
	131169675468160 [label=MaxPool2DWithIndicesBackward0]
	131169675464896 -> 131169675468160
	131169675464896 [label=ReluBackward0]
	131169675468352 -> 131169675464896
	131169675468352 [label=ConvolutionBackward0]
	131169675468592 -> 131169675468352
	131169675468592 [label=ReluBackward0]
	131169675468880 -> 131169675468592
	131169675468880 [label=ConvolutionBackward0]
	131169675468928 -> 131169675468880
	131169675033600 [label="enc1.layers.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	131169675033600 -> 131169675468928
	131169675468928 [label=AccumulateGrad]
	131169675468784 -> 131169675468880
	131169675033680 [label="enc1.layers.0.bias
 (16)" fillcolor=lightblue]
	131169675033680 -> 131169675468784
	131169675468784 [label=AccumulateGrad]
	131169675468544 -> 131169675468352
	131169675033840 [label="enc1.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	131169675033840 -> 131169675468544
	131169675468544 [label=AccumulateGrad]
	131169675468688 -> 131169675468352
	131169675033920 [label="enc1.layers.2.bias
 (16)" fillcolor=lightblue]
	131169675033920 -> 131169675468688
	131169675468688 [label=AccumulateGrad]
	131169675468016 -> 131169675468112
	131169675034080 [label="enc2.layers.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	131169675034080 -> 131169675468016
	131169675468016 [label=AccumulateGrad]
	131169675468256 -> 131169675468112
	131169675034160 [label="enc2.layers.0.bias
 (32)" fillcolor=lightblue]
	131169675034160 -> 131169675468256
	131169675468256 [label=AccumulateGrad]
	131169675467680 -> 131169675467776
	131169675034320 [label="enc2.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	131169675034320 -> 131169675467680
	131169675467680 [label=AccumulateGrad]
	131169675467920 -> 131169675467776
	131169675034400 [label="enc2.layers.2.bias
 (32)" fillcolor=lightblue]
	131169675034400 -> 131169675467920
	131169675467920 [label=AccumulateGrad]
	131169675467488 -> 131169675467440
	131169675034560 [label="enc3.layers.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	131169675034560 -> 131169675467488
	131169675467488 [label=AccumulateGrad]
	131169675467344 -> 131169675467440
	131169675493456 [label="enc3.layers.0.bias
 (64)" fillcolor=lightblue]
	131169675493456 -> 131169675467344
	131169675467344 [label=AccumulateGrad]
	131169675467200 -> 131169675467152
	131169675493616 [label="enc3.layers.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	131169675493616 -> 131169675467200
	131169675467200 [label=AccumulateGrad]
	131169675467056 -> 131169675467152
	131169675493696 [label="enc3.layers.2.bias
 (64)" fillcolor=lightblue]
	131169675493696 -> 131169675467056
	131169675467056 [label=AccumulateGrad]
	131169675466864 -> 131169675466768
	131169675493856 [label="dec3.up.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	131169675493856 -> 131169675466864
	131169675466864 [label=AccumulateGrad]
	131169675466816 -> 131169675466768
	131169675493936 [label="dec3.up.bias
 (32)" fillcolor=lightblue]
	131169675493936 -> 131169675466816
	131169675466816 [label=AccumulateGrad]
	131169675466720 -> 131169675466576
	131169675466528 -> 131169675466480
	131169675494096 [label="dec3.conv.layers.0.weight
 (32, 96, 3, 3)" fillcolor=lightblue]
	131169675494096 -> 131169675466528
	131169675466528 [label=AccumulateGrad]
	131169675466384 -> 131169675466480
	131169675494176 [label="dec3.conv.layers.0.bias
 (32)" fillcolor=lightblue]
	131169675494176 -> 131169675466384
	131169675466384 [label=AccumulateGrad]
	131169675466240 -> 131169675466192
	131169675494336 [label="dec3.conv.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	131169675494336 -> 131169675466240
	131169675466240 [label=AccumulateGrad]
	131169675466096 -> 131169675466192
	131169675494416 [label="dec3.conv.layers.2.bias
 (32)" fillcolor=lightblue]
	131169675494416 -> 131169675466096
	131169675466096 [label=AccumulateGrad]
	131169675465952 -> 131169675465856
	131169675494576 [label="dec2.up.weight
 (32, 16, 2, 2)" fillcolor=lightblue]
	131169675494576 -> 131169675465952
	131169675465952 [label=AccumulateGrad]
	131169675465904 -> 131169675465856
	131169675494656 [label="dec2.up.bias
 (16)" fillcolor=lightblue]
	131169675494656 -> 131169675465904
	131169675465904 [label=AccumulateGrad]
	131169675465808 -> 131169675465664
	131169675465616 -> 131169675465568
	131169675494816 [label="dec2.conv.layers.0.weight
 (16, 48, 3, 3)" fillcolor=lightblue]
	131169675494816 -> 131169675465616
	131169675465616 [label=AccumulateGrad]
	131169675465472 -> 131169675465568
	131169675494896 [label="dec2.conv.layers.0.bias
 (16)" fillcolor=lightblue]
	131169675494896 -> 131169675465472
	131169675465472 [label=AccumulateGrad]
	131169675465328 -> 131169675465280
	131169675495056 [label="dec2.conv.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	131169675495056 -> 131169675465328
	131169675465328 [label=AccumulateGrad]
	131169675465184 -> 131169675465280
	131169675495136 [label="dec2.conv.layers.2.bias
 (16)" fillcolor=lightblue]
	131169675495136 -> 131169675465184
	131169675465184 [label=AccumulateGrad]
	131169675465040 -> 131169675464944
	131169675495296 [label="dec1.up.weight
 (16, 8, 2, 2)" fillcolor=lightblue]
	131169675495296 -> 131169675465040
	131169675465040 [label=AccumulateGrad]
	131169675464992 -> 131169675464944
	131169675495376 [label="dec1.up.bias
 (8)" fillcolor=lightblue]
	131169675495376 -> 131169675464992
	131169675464992 [label=AccumulateGrad]
	131169675464896 -> 131169675464608
	131169675464656 -> 131169675464704
	131169675495536 [label="dec1.conv.layers.0.weight
 (8, 24, 3, 3)" fillcolor=lightblue]
	131169675495536 -> 131169675464656
	131169675464656 [label=AccumulateGrad]
	131169675464800 -> 131169675464704
	131169675495616 [label="dec1.conv.layers.0.bias
 (8)" fillcolor=lightblue]
	131169675495616 -> 131169675464800
	131169675464800 [label=AccumulateGrad]
	131169675464128 -> 131169675464224
	131169675495776 [label="dec1.conv.layers.2.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	131169675495776 -> 131169675464128
	131169675464128 [label=AccumulateGrad]
	131169675463888 -> 131169675464224
	131169675495856 [label="dec1.conv.layers.2.bias
 (8)" fillcolor=lightblue]
	131169675495856 -> 131169675463888
	131169675463888 [label=AccumulateGrad]
	131169677317296 -> 131169679057360
	131169675496016 [label="conv.weight
 (1, 8, 1, 1)" fillcolor=lightblue]
	131169675496016 -> 131169677317296
	131169677317296 [label=AccumulateGrad]
	131169675464368 -> 131169679057360
	131169675496096 [label="conv.bias
 (1)" fillcolor=lightblue]
	131169675496096 -> 131169675464368
	131169675464368 [label=AccumulateGrad]
	131169679057360 -> 131169675496976
}
