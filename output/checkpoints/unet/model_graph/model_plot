digraph {
	graph [size="30.0,30.0"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	134157886474752 [label="
 (2, 1, 128, 128)" fillcolor=darkolivegreen1]
	134157888721856 [label=ConvolutionBackward0]
	134157888720992 -> 134157888721856
	134157888720992 [label=ReluBackward0]
	134157888722144 -> 134157888720992
	134157888722144 [label=ConvolutionBackward0]
	134157888721328 -> 134157888722144
	134157888721328 [label=ReluBackward0]
	134157888722528 -> 134157888721328
	134157888722528 [label=ConvolutionBackward0]
	134157888722288 -> 134157888722528
	134157888722288 [label=CatBackward0]
	134157888722480 -> 134157888722288
	134157888722480 [label=ConvolutionBackward0]
	134157888722816 -> 134157888722480
	134157888722816 [label=ReluBackward0]
	134157888723008 -> 134157888722816
	134157888723008 [label=ConvolutionBackward0]
	134157888723200 -> 134157888723008
	134157888723200 [label=ReluBackward0]
	134157888722624 -> 134157888723200
	134157888722624 [label=ConvolutionBackward0]
	134157888723392 -> 134157888722624
	134157888723392 [label=CatBackward0]
	134157888722432 -> 134157888723392
	134157888722432 [label=ConvolutionBackward0]
	134157888723440 -> 134157888722432
	134157888723440 [label=ReluBackward0]
	134157888723824 -> 134157888723440
	134157888723824 [label=ConvolutionBackward0]
	134157888724112 -> 134157888723824
	134157888724112 [label=ReluBackward0]
	134157888723968 -> 134157888724112
	134157888723968 [label=ConvolutionBackward0]
	134157888724544 -> 134157888723968
	134157888724544 [label=CatBackward0]
	134157888724496 -> 134157888724544
	134157888724496 [label=ConvolutionBackward0]
	134157888724880 -> 134157888724496
	134157888724880 [label=MaxPool2DWithIndicesBackward0]
	134157888724688 -> 134157888724880
	134157888724688 [label=ReluBackward0]
	134157888724640 -> 134157888724688
	134157888724640 [label=ConvolutionBackward0]
	134157888723488 -> 134157888724640
	134157888723488 [label=ReluBackward0]
	134157888726944 -> 134157888723488
	134157888726944 [label=ConvolutionBackward0]
	134157888725648 -> 134157888726944
	134157888725648 [label=MaxPool2DWithIndicesBackward0]
	134157888725072 -> 134157888725648
	134157888725072 [label=ReluBackward0]
	134157888724976 -> 134157888725072
	134157888724976 [label=ConvolutionBackward0]
	134157888725600 -> 134157888724976
	134157888725600 [label=ReluBackward0]
	134157888725744 -> 134157888725600
	134157888725744 [label=ConvolutionBackward0]
	134157888725840 -> 134157888725744
	134157888725840 [label=MaxPool2DWithIndicesBackward0]
	134157888722336 -> 134157888725840
	134157888722336 [label=ReluBackward0]
	134157888726512 -> 134157888722336
	134157888726512 [label=ConvolutionBackward0]
	134157888726416 -> 134157888726512
	134157888726416 [label=ReluBackward0]
	134157888723152 -> 134157888726416
	134157888723152 [label=ConvolutionBackward0]
	134157888727136 -> 134157888723152
	134157886388288 [label="enc1.layers.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	134157886388288 -> 134157888727136
	134157888727136 [label=AccumulateGrad]
	134157888726560 -> 134157888723152
	134157886388368 [label="enc1.layers.0.bias
 (16)" fillcolor=lightblue]
	134157886388368 -> 134157888726560
	134157888726560 [label=AccumulateGrad]
	134157888726656 -> 134157888726512
	134157886388528 [label="enc1.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	134157886388528 -> 134157888726656
	134157888726656 [label=AccumulateGrad]
	134157888726848 -> 134157888726512
	134157886388608 [label="enc1.layers.2.bias
 (16)" fillcolor=lightblue]
	134157886388608 -> 134157888726848
	134157888726848 [label=AccumulateGrad]
	134157888726128 -> 134157888725744
	134157886388768 [label="enc2.layers.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	134157886388768 -> 134157888726128
	134157888726128 [label=AccumulateGrad]
	134157888726176 -> 134157888725744
	134157886388848 [label="enc2.layers.0.bias
 (32)" fillcolor=lightblue]
	134157886388848 -> 134157888726176
	134157888726176 [label=AccumulateGrad]
	134157888725792 -> 134157888724976
	134157886389008 [label="enc2.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	134157886389008 -> 134157888725792
	134157888725792 [label=AccumulateGrad]
	134157888725888 -> 134157888724976
	134157886389088 [label="enc2.layers.2.bias
 (32)" fillcolor=lightblue]
	134157886389088 -> 134157888725888
	134157888725888 [label=AccumulateGrad]
	134157888725120 -> 134157888726944
	134157886389248 [label="enc3.layers.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	134157886389248 -> 134157888725120
	134157888725120 [label=AccumulateGrad]
	134157888725168 -> 134157888726944
	134157886389328 [label="enc3.layers.0.bias
 (64)" fillcolor=lightblue]
	134157886389328 -> 134157888725168
	134157888725168 [label=AccumulateGrad]
	134157888724784 -> 134157888724640
	134157886389488 [label="enc3.layers.2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	134157886389488 -> 134157888724784
	134157888724784 [label=AccumulateGrad]
	134157888725024 -> 134157888724640
	134157886389568 [label="enc3.layers.2.bias
 (64)" fillcolor=lightblue]
	134157886389568 -> 134157888725024
	134157888725024 [label=AccumulateGrad]
	134157888724448 -> 134157888724496
	134157886389728 [label="dec3.up.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	134157886389728 -> 134157888724448
	134157888724448 [label=AccumulateGrad]
	134157888724304 -> 134157888724496
	134157886389808 [label="dec3.up.bias
 (32)" fillcolor=lightblue]
	134157886389808 -> 134157888724304
	134157888724304 [label=AccumulateGrad]
	134157888724688 -> 134157888724544
	134157888724064 -> 134157888723968
	134157886389968 [label="dec3.conv.layers.0.weight
 (32, 96, 3, 3)" fillcolor=lightblue]
	134157886389968 -> 134157888724064
	134157888724064 [label=AccumulateGrad]
	134157888724352 -> 134157888723968
	134157886390048 [label="dec3.conv.layers.0.bias
 (32)" fillcolor=lightblue]
	134157886390048 -> 134157888724352
	134157888724352 [label=AccumulateGrad]
	134157888724208 -> 134157888723824
	134157886390208 [label="dec3.conv.layers.2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	134157886390208 -> 134157888724208
	134157888724208 [label=AccumulateGrad]
	134157888723776 -> 134157888723824
	134157886472272 [label="dec3.conv.layers.2.bias
 (32)" fillcolor=lightblue]
	134157886472272 -> 134157888723776
	134157888723776 [label=AccumulateGrad]
	134157888723728 -> 134157888722432
	134157886472432 [label="dec2.up.weight
 (32, 16, 2, 2)" fillcolor=lightblue]
	134157886472432 -> 134157888723728
	134157888723728 [label=AccumulateGrad]
	134157888723872 -> 134157888722432
	134157886472512 [label="dec2.up.bias
 (16)" fillcolor=lightblue]
	134157886472512 -> 134157888723872
	134157888723872 [label=AccumulateGrad]
	134157888725072 -> 134157888723392
	134157888723536 -> 134157888722624
	134157886472672 [label="dec2.conv.layers.0.weight
 (16, 48, 3, 3)" fillcolor=lightblue]
	134157886472672 -> 134157888723536
	134157888723536 [label=AccumulateGrad]
	134157888723344 -> 134157888722624
	134157886472752 [label="dec2.conv.layers.0.bias
 (16)" fillcolor=lightblue]
	134157886472752 -> 134157888723344
	134157888723344 [label=AccumulateGrad]
	134157888721568 -> 134157888723008
	134157886472912 [label="dec2.conv.layers.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	134157886472912 -> 134157888721568
	134157888721568 [label=AccumulateGrad]
	134157888722912 -> 134157888723008
	134157886472992 [label="dec2.conv.layers.2.bias
 (16)" fillcolor=lightblue]
	134157886472992 -> 134157888722912
	134157888722912 [label=AccumulateGrad]
	134157888722768 -> 134157888722480
	134157886473152 [label="dec1.up.weight
 (16, 8, 2, 2)" fillcolor=lightblue]
	134157886473152 -> 134157888722768
	134157888722768 [label=AccumulateGrad]
	134157888722864 -> 134157888722480
	134157886473232 [label="dec1.up.bias
 (8)" fillcolor=lightblue]
	134157886473232 -> 134157888722864
	134157888722864 [label=AccumulateGrad]
	134157888722336 -> 134157888722288
	134157888721952 -> 134157888722528
	134157886473392 [label="dec1.conv.layers.0.weight
 (8, 24, 3, 3)" fillcolor=lightblue]
	134157886473392 -> 134157888721952
	134157888721952 [label=AccumulateGrad]
	134157888721904 -> 134157888722528
	134157886473472 [label="dec1.conv.layers.0.bias
 (8)" fillcolor=lightblue]
	134157886473472 -> 134157888721904
	134157888721904 [label=AccumulateGrad]
	134157888721616 -> 134157888722144
	134157886473632 [label="dec1.conv.layers.2.weight
 (8, 8, 3, 3)" fillcolor=lightblue]
	134157886473632 -> 134157888721616
	134157888721616 [label=AccumulateGrad]
	134157888722192 -> 134157888722144
	134157886473712 [label="dec1.conv.layers.2.bias
 (8)" fillcolor=lightblue]
	134157886473712 -> 134157888722192
	134157888722192 [label=AccumulateGrad]
	134157888721760 -> 134157888721856
	134157886473872 [label="conv.weight
 (1, 8, 1, 1)" fillcolor=lightblue]
	134157886473872 -> 134157888721760
	134157888721760 [label=AccumulateGrad]
	134157888719120 -> 134157888721856
	134157886473952 [label="conv.bias
 (1)" fillcolor=lightblue]
	134157886473952 -> 134157888719120
	134157888719120 [label=AccumulateGrad]
	134157888721856 -> 134157886474752
}
